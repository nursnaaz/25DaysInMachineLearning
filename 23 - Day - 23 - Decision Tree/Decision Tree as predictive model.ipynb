{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\", sep = ';')\n",
    "y = df.pop('quality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.columns:\n",
    "    df[i] = df[i].fillna(np.mean(df[i]))\n",
    "train, test, y_train, y_test = train_test_split(df, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score baseline: 0.5153061224489796\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(train, y_train)\n",
    "y_pred = lr.predict(test)\n",
    "print('Accuracy score baseline:', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_predict(train, test, y_train, y_test, scaler, max_depth, \n",
    "                criterion = 'entropy', max_features = 1, min_samples_split = 4):\n",
    "    train_scaled = scaler.fit_transform(train)\n",
    "    test_scaled = scaler.transform(test)        \n",
    "    dt = DecisionTreeClassifier(criterion = criterion, max_depth=max_depth, \n",
    "                                 max_features=max_features,\n",
    "                               min_samples_split=min_samples_split)\n",
    "    dt.fit(train_scaled, y_train)\n",
    "    y_pred = dt.predict(test_scaled)\n",
    "    print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5989795918367347\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(train, y_train)\n",
    "y_pred = dt.predict(test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max depth tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score using max_depth = 1: 0.44081632653061226\n",
      "Accuracy score using max_depth = 2: 0.4530612244897959\n",
      "Accuracy score using max_depth = 3: 0.46224489795918366\n",
      "Accuracy score using max_depth = 4: 0.5010204081632653\n",
      "Accuracy score using max_depth = 5: 0.4530612244897959\n",
      "Accuracy score using max_depth = 6: 0.4928571428571429\n",
      "Accuracy score using max_depth = 7: 0.5091836734693878\n",
      "Accuracy score using max_depth = 8: 0.5224489795918368\n",
      "Accuracy score using max_depth = 9: 0.47959183673469385\n",
      "Accuracy score using max_depth = 10: 0.5142857142857142\n",
      "Accuracy score using max_depth = 11: 0.5091836734693878\n",
      "Accuracy score using max_depth = 12: 0.5469387755102041\n",
      "Accuracy score using max_depth = 13: 0.5173469387755102\n",
      "Accuracy score using max_depth = 14: 0.5306122448979592\n",
      "Accuracy score using max_depth = 15: 0.5673469387755102\n",
      "Accuracy score using max_depth = 16: 0.5826530612244898\n",
      "Accuracy score using max_depth = 17: 0.5479591836734694\n",
      "Accuracy score using max_depth = 18: 0.5959183673469388\n",
      "Accuracy score using max_depth = 19: 0.5510204081632653\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 20):\n",
    "    print('Accuracy score using max_depth =', i, end = ': ')\n",
    "    fit_predict(train, test, y_train, y_test, StandardScaler(), i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max features tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score using max features = 0.1: 0.5551020408163265\n",
      "Accuracy score using max features = 0.2: 0.5989795918367347\n",
      "Accuracy score using max features = 0.30000000000000004: 0.5816326530612245\n",
      "Accuracy score using max features = 0.4: 0.6040816326530613\n",
      "Accuracy score using max features = 0.5: 0.5887755102040816\n",
      "Accuracy score using max features = 0.6: 0.5755102040816327\n",
      "Accuracy score using max features = 0.7000000000000001: 0.5959183673469388\n",
      "Accuracy score using max features = 0.8: 0.5979591836734693\n",
      "Accuracy score using max features = 0.9: 0.5846938775510204\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(0.1, 1.0, 0.1):\n",
    "    print('Accuracy score using max features =', i, end = ': ')\n",
    "    fit_predict(train, test, y_train, y_test, StandardScaler(), max_depth = 18, max_features=i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Min samples split tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score using min samples split = 2: 0.6224489795918368\n",
      "Accuracy score using min samples split = 3: 0.5989795918367347\n",
      "Accuracy score using min samples split = 4: 0.5908163265306122\n",
      "Accuracy score using min samples split = 5: 0.5897959183673469\n",
      "Accuracy score using min samples split = 6: 0.563265306122449\n",
      "Accuracy score using min samples split = 7: 0.5418367346938775\n",
      "Accuracy score using min samples split = 8: 0.5428571428571428\n",
      "Accuracy score using min samples split = 9: 0.563265306122449\n"
     ]
    }
   ],
   "source": [
    "for i in range(2, 10):\n",
    "    print('Accuracy score using min samples split =', i, end = ': ')\n",
    "    fit_predict(train, test, y_train, y_test, StandardScaler(), 18, max_features=0.3, min_samples_split=i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criterion tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score using criterion = gini: 0.6153061224489796\n",
      "Accuracy score using criterion = entropy: 0.613265306122449\n"
     ]
    }
   ],
   "source": [
    "for i in ['gini', 'entropy']:\n",
    "    print('Accuracy score using criterion =', i, end = ': ')\n",
    "    fit_predict(train, test, y_train, y_test, StandardScaler(), 18, \n",
    "                max_features=0.3, min_samples_split=2, criterion = 'entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_poly(train,test,degree):\n",
    "    poly = PolynomialFeatures(degree=degree)\n",
    "    train_poly = poly.fit_transform(train)\n",
    "    test_poly = poly.fit_transform(test)\n",
    "    return train_poly,test_poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polynomial degree 1\n",
      "0.610204081632653\n",
      "----------\n",
      "Polynomial degree 2\n",
      "0.6336734693877552\n",
      "----------\n",
      "Polynomial degree 3\n",
      "0.6081632653061224\n",
      "----------\n",
      "Polynomial degree 4\n",
      "0.6020408163265306\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "for degree in [1,2,3,4]:\n",
    "    train_poly, test_poly = create_poly(train, test, degree)\n",
    "    print('Polynomial degree',degree)\n",
    "    fit_predict(train_poly, test_poly, y_train, y_test, StandardScaler(), 18, \n",
    "                max_features=0.3, min_samples_split=2, criterion = 'entropy')\n",
    "    print(10*'-')\n",
    "    \n",
    "train_poly, test_poly = create_poly(train, test, 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional feature engineering:\n",
      "0.5989795918367347\n",
      "0.613265306122449\n"
     ]
    }
   ],
   "source": [
    "def feat_eng(df):\n",
    "    df['eng1'] = df['fixed acidity'] * df['pH']\n",
    "    df['eng2'] = df['total sulfur dioxide'] / df['free sulfur dioxide']\n",
    "    df['eng3'] = df['sulphates'] / df['chlorides']\n",
    "    df['eng4'] = df['chlorides'] / df['sulphates']\n",
    "    return df\n",
    "\n",
    "train = feat_eng(train)\n",
    "test = feat_eng(test)\n",
    "\n",
    "print('Additional feature engineering:')\n",
    "\n",
    "fit_predict(train, test, y_train, y_test, StandardScaler(), 18, \n",
    "                max_features=0.3, min_samples_split=2, criterion = 'entropy')\n",
    "\n",
    "train_poly, test_poly = create_poly(train, test, 2)\n",
    "\n",
    "fit_predict(train_poly, test_poly, y_train, y_test, StandardScaler(), 18, \n",
    "                max_features=0.3, min_samples_split=2, criterion = 'entropy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall improvement is 21.63 %\n"
     ]
    }
   ],
   "source": [
    "original_score = 0.514285714286\n",
    "best_score = 0.625510204082\n",
    "improvement = np.abs(np.round(100*(original_score - best_score)/original_score,2))\n",
    "print('overall improvement is {} %'.format(improvement))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pydotplus\n",
    "from sklearn import tree\n",
    "import collections\n",
    "\n",
    "dot_data = tree.export_graphviz(dt,\n",
    "                                feature_names=df.columns,\n",
    "                                out_file=None,\n",
    "                                filled=True,\n",
    "                                rounded=True)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data)\n",
    "\n",
    "colors = ('turquoise', 'orange')\n",
    "edges = collections.defaultdict(list)\n",
    "\n",
    "for edge in graph.get_edge_list():\n",
    "    edges[edge.get_source()].append(int(edge.get_destination()))\n",
    "\n",
    "for edge in edges:\n",
    "    edges[edge].sort()    \n",
    "    for i in range(2):\n",
    "        dest = graph.get_node(str(edges[edge][i]))[0]\n",
    "        dest.set_fillcolor(colors[i])\n",
    "\n",
    "graph.write_png('tree1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 6, 6, ..., 6, 7, 6])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',\n",
       "       'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density',\n",
       "       'pH', 'sulphates', 'alcohol'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
